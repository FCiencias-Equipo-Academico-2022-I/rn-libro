\section{Esquema general entrenamiento}
 En este capítulo vamos a trabajar con el entrenamiento, en esta sección abordaremos primero el esquema general del entremiento así pues veamos la derivación del primer algoritmo de entrenamiento para perceptores multicapa le llamó primero porque también es ahorita el más utilizado el más común y el primero que se estableció históricamente vamos a ver cómo se entrenan las redes neuronales primero que nada vamos a definir en qué consiste aprender algo cuando estamos hablando concretamente de redes neuronales recordemos que ya habíamos hablado antes de los espacios de y poder que realmente aprender se trata de encontrar una función dentro de un espacio de funciones posibles y la característica que tiene esta función es que aproxima una función que modela algún fenómeno que nos está interesando a aprender entonces vamos a definir el problema de aprendizaje para un percepción multicapa de la siguiente manera dada una arquitectura de red neuronal encontrar los pesos tales que la función definida por la red neuronal aproxime hasta cierta tolerancia la función de interés f x voy a entrar en detalles sobre esta anotación x son nuestros datos de entrada pueden consistir en diferentes características dependiendo del problema del que estamos trabajando puede ser por ejemplo segmentos de alguna canción pueden ser imágenes de audio pueden ser valores referentes a características de una casa tratando de predecir sus preciosos en su región entonces la equis son precisamente todas esas características en general x puede ser un suelo ejemplar que sería el que va a comenzar nuestra función de tal manera que tengamos fx que va a ser mapeado a alguna clase estas redes que estamos viendo aquí lo que están haciendo es resolver problemas de clasificación queremos saber si dada una imagen es por ejemplo una casa una vaca un perro dada una canción si es una canción triste una canción alegre una canción tranquila entonces estamos mapeando podríamos pensarlo así al espacio de clases entonces la función f x sería aquella función ideal que recibe una imagen y nos dice inmediatamente que es recibe un cacho de una canción y nos dice inmediatamente a qué género pertenece o qué estado de ánimo representa lo que nosotros vamos a hacer con la red neuronal es tratar de aproximar esta función que asumimos que existe en el universo y ahora estamos tratando de ver cómo calcularla este h viene precisamente del nombre hipótesis porque es la hipótesis que está planteando nuestra red neuronal puede ser que sea una buena aproximación de esta función o puede ser que sea mala lo que nosotros queremos hacer es encontrar pesos en esta red neuronal tal que nuestra aproximación sea lo mejor posible entonces aquí entra también el elemento de cierta tolerancia es probable que a veces no podamos aprender exactamente esta función y que siempre encontremos errores o alguno que otro ejemplar que no va a ser clasificado correctamente bueno dependido de nuestro contexto tendremos que decir hasta qué momento se pueden considerar perdonables esos errores o si tenemos que continuar busca recordemos que en general tener demasiada precisión en los datos con los que entrenamos puede significar que estamos aprendiendo ruido y que después cuando recibamos datos nuevos no vamos a tener buenas predicciones entonces aquí vamos a tener que ir aprendiendo a lo largo del curso cómo podemos evaluar bueno cómo fijar hasta dónde entraría está tolerancia entonces uno se acostumbra entrenar a las redes neuronales así insistir una vez más en este punto una red neuronal con un conjunto de pesos dados ya define una función es a la que le estamos llamando h de zeta en los vídeos anteriores aprendimos a asignar estos pesos inclusive manualmente eligiendo nosotros una recta en una representación gráfica entonces ponerle los pesos a la red o tener sin presencia mente una red con pesos ya es una función a veces podemos encontrar directamente esos pesos de tal manera que nos modelan correctamente la función que nosotros queremos a veces el problema va a ser precisamente que no conocemos pesos pesos y los queremos encontrar ahí es donde va a entrar el elemento de aprendizaje entonces a qué le vamos a llamar entrenamiento o cómo vamos a entrenar a una red para que aproxime cada vez más a la función que nosotros queremos el mejor nuestro punto inicial es una función que no se parece como cambiamos eso como lo arreglamos la estrategia de entrenamiento para encontrar un conjunto de pesos que satisfaga este requerimiento o sea aproximar correctamente la función consiste en lo siguiente uno definir una función de error o pérdida le vamos a llamar j en este momento otra anotación común que encontrarán en internet es el de los perdidas que mida la distancia entre los valores deseados y los valores obtenidos con un conjunto de pesos dados z entonces recordemos aquí que estamos en un tipo de entrenamiento supervisado este es para casos de aprendizaje supervisado donde tenemos un conjunto de valores deseados es decir ya sabemos que tenemos una función que queremos aproxima el siguiente punto es utilizar alguna técnica de optimización de funciones que minimice este error y en este momento es querido enfatizar la parte alguna técnica puede ser cualquiera cualquier técnica de optimización que nos permite minimizar el error la podemos intentar utilizar para entrenar redes neuronales algunas funcionarán mejor que otras dependiendo del espacio en el que estemos buscando pero podemos elegir entre todas ellas en particular en algún momento vamos a ver otra familia que no entra en las creamos ahorita como son los algoritmos genéticos también es una técnica de optimización entonces también se puede llegar a utilizar entonces tanto la arquitectura considerar como la función de error y la técnica de optimización dependerá del tipo de función que se desee aproximar ahorita vamos a verlo de manera abstracta de manera general un poco a poco a lo largo del curso iremos viendo precisamente diferentes tipos de funciones y qué arquitecturas se recomiendan qué estrategias funcionan para entre vamos a ver ahorita un esquema general este esquema es el que se conoce como entrenamiento por retropropagación y propagación hacia atrás también se le suele llamar en inglés realmente el único nombre es barack corporation también frecuentemente se encontrarán que en la literatura en español algunos no lo traducen y lo dejan tal cual en inglés vamos a utilizar aquí usualmente el término retro propagación que significa bueno ustedes habrán dado cuenta de que tenemos un primer alimento que era alimentación hacia adelante en inglés feedforward lo que vamos a hacer para entrenar a la red es recorrer los pesos en dirección inversa desde el resultado hacia los datos de entrada y por eso lleva precisamente el nombre contrario al algoritmo de evaluación de la red normal bien entonces este algoritmo consiste en la siguiente combinación este es históricamente en primer lugar utilizar la regla de la cadena para obtener el gradiente de la función de error con respecto al conjunto de pesos dado un conjunto de datos de entrenamiento x con sus etiquetas el segundo paso utilizar descenso por el gradiente para encontrar un mínimo lo suficientemente bueno de la función de error aquí es donde entra precisamente la perspectiva histórica utilizar descenso por el gradiente es la técnica más sencilla que existe por eso es interesante empezar por aquí precisamente a plantear la metodología pero en la actualidad se utilizan ya métodos de optimización que dependen del gradiente bastante más avanzados entonces en qué consiste conceptualmente esta idea en que nosotros al inicio no sabemos cuánto deben de valer los pesos para modelar correctamente la función entonces vamos a comenzar con una asignación aleatoria de pesos suponiendo que éste sea una versión caricaturesca de una semana muy simple vamos a suponer que esta parte de aquí abajo representa el conjunto de pesos en nuestra red neuronal elegimos algún punto al azar todo ese punto calculamos el error que está cometiendo la red al comparar los datos que obtuvo la red neuronal al aplicar feedforward sobre nuestros datos de entrada con respecto a la respuesta que queríamos que nos dieran si nosotros asignamos valores al azar evidentemente no tenemos por qué esperar que la aproximación sea buena lo que va a ser ahora por nosotros el descenso por el gradiente es ir modificando poco a poco estos pesos para que nosotros tengamos ahora una nueva aproximación y cada vez nos acerque más a una región donde el error sea más pequeño y aquí importa también muy bien en la parte que dice para encontrar un mínimo lo que es el descenso por el gradiente es lo siguiente comenzamos con un conjunto de propuestas para nuestros parámetros de tal calculamos el gradiente es decir las derivadas de la función de error con respecto a los parámetros de aquí vamos a obtener el gradiente este gradiente lo que nos va a dar es la dirección de máximo ascenso de la función de error al agregar este signo menos lo que estamos haciendo es invertir ese vector de la dirección de máximo acceso y obtener por consiguiente la dirección de máximo descenso entonces con este vector que básicamente aproxima en la tangente de la curva pero además nos da la dirección en la que va a descender lo más rápido posible lo que hacemos es modificar los parámetros que habíamos propuesto exactamente en esa dirección para que nos lleve lo más rápido posible por donde está descendiendo la pena y con eso calculamos la nueva propuesta de parámetros para la red aquí les dijo que es un dibujo un poco caricaturesco porque es un segmento de paraboloide en el caso de las redes neuronales cuando ya tenemos varias neuronas y muchas conexiones la curva no es un paraboloide con un único mínimo en realidad vamos a tener un montón de mínimos y máximos locales extendiéndose en varias direcciones junto con algunas regiones un poco peligro grandes picos y es un paisaje bastante interesante lo que va a hacer por nosotros entonces descenso por el gradiente es acercarnos al mínimo más cercano que nosotros tengamos como se entrena entonces realmente una red neuronal bueno como el mínimo el que lleguemos depende de el conjunto original que hayamos dado de parámetros es para el entrenamiento lo que vamos a hacer es inicializar aleatoriamente estos datos para obtener puntos en diferentes regiones del espacio y repetir el entrenamiento varias veces aquí el entrenamiento que nos logre llevar al mejor mínimo que satisfagan nuestros requerimientos de haber aproximado lo suficientemente bien la función ese es el conjunto con el que nos vamos a quedar una vez que ya hemos evaluado nuestra red y que hemos visto que es buena para hacer predicciones inclusive en otros conjuntos de datos que no sean con los que entrenamos y así que para eso nos sirve el conjunto de validación entonces podremos decir que ya tenemos una red que podemos utilizar para hacer adicciones en otras versiones algunos sistemas a la mejor hasta podrían guardar una colección de las redes que quedaron mejores entrenadas y utilizar algún sistema de votación para tomar decisiones al momento de utilizarlas ya en producción lo que estamos viendo aquí a la derecha es una imagen de los cortes que se podrían hacer horizontalmente de esta misma imagen entonces también podemos visualizar a nuestro conjunto de parámetros z y coordenadas sobre este plano y en estas que son las curvas de nivel podemos ir tratar todo visualizar buenas ya que hasta el mínimo hacía que estaría como está subiendo el paraboloide y podemos ver también como la dirección negativa del gradiente pues nos iría dirigiendo poco a poco hacia este centro donde tenemos uno entonces actualmente se puede cambiar la técnica de optimización por algún otro método más avanzado también dependiente del gradiente el hecho de que depende del gradiente pues va a ser que en la siguiente sección sea sumamente importante que es como calculamos el gradiente de la función de error la derivación original utilizaba diferencias al cuadrado como función de error recordemos que es aquella en la que deseamos cuánto es lo que quiero obtener menos mi hipótesis de lo que evalúa un mínimo función de la red neuronal sobre los datos elevados al cuadrado y después sumamos sobre todas las y todos los ejemplares entonces esta fue la primera que se utilizó sin embargo se ha comprobado que esta función es adecuada para problemas de regresión pero para problemas de clasificación es mejor utilizar otra que se le conoce como entropía cruzada y ven artículos un poco viejitos o inclusive de otros campos van a ver que es muy frecuente encontrar diferencias al cuadrado por ello si quieren ver esa derivación se puede consultar en el libro de rosalino link les recomiendo la tercera edición creo que la anotación es más clara en la tercera edición que en la segunda lo que vamos a hacer nosotros aquí es ver la derivación con entropía cruzada que es básicamente ya el estándar cuando queremos empezar a trabajar con problemas de clasificación vamos a ver también que tiene algunas propiedades bastante bonitas y nos va a facilitar las cosas.
