\section{Normalización y normalización por lotes}

Un factor importante a tomar en cuenta para un buen desempeño del entrenamiento son las magnitudes del datos de entrada a la red. Entonces para mejorar el desempeño del algoritmo de optimización nos conviene pre-procesar los datos de entrada. Esto mediante una técnica que se llama normalización (\emph{normalization} en inglés).

La técnica que hemos utilizado son técnicas de optimización basadas en el gradiente, la cual a una función de error se calcula el gradiente, este nos da la dirección del máximo descenso, para  hacer aproximaciones discretas en los parámetros hasta que tratemos de llegar al mínimo de la función.
 
Para poder realizar lo anterior necesitamo que las magnitudes de los datos de entrada no esten muy dispersas, es decir que no nos encontremos con situaciones donde estemos manejando decimales para unos datos y para otros unidades de millones. En estos casos la función de error nunca va a terminar de ajustarse correctamente a estos datos, pues en ocaciónes los parametros para ajustar, van a avanzar de forma distorsionada. Dando la impresión que para unos datos el gradiente avanza muy rapido al centro, mientras que para otros datos avanza muy lento, esto porque vamos a tener curvas de nivel demasiado elípticas (ver la \fref{fig:curvasNivel}), entonces al tomar la dirección que nos de el gradiente, nos va a mover desplazar muy violentamente en algunas y muy lento para otras. Cuando se intente hacer descenso por el gradiente en estas regiones lo que va a pasar es que el vector va a oscilar muy violentamente y  nos va a dificultar mucho llegar al minimo.

Por el contrario, si las magnitudes con las que trabajamos son del mismo orden y contribuyen numéricamente de una manera más proporcionada al error, entonces vamos a tener curvas de nivel  más circulares (ver la \fref{fig:curvasNivel}). Cuando calculemos el gradiente, la perpendicular se aproximará durante más tiempo a la dirección de máximo descenso. 

\begin{figure}[H]
 \centering
 \includegraphics[scale=0.5]{../Figuras/curvasDeNivel.png}
 \caption{Izq: J la función de error con alta excentricidad. Der: J con curvas de nivel tendiendo a círculos}
 \label{fig:curvasNivel}
\end{figure}

Entonces para asegurar un buen desenso por el grandiente, vamos a preferir siempre trabajar con curvas de nivel circulares, para esto vamos a usar la normalización.

La normalización conciste en centrar los datos aproximadamente en el intervalo $[-1.0, 1.0]$, este intervalo no es estricto para todas las redes basta con definir las magnitudes en un intervalo aceptable para tener curvas de nivel circulares. 

Existen varias fórmulas para realizar la normalización, se sugiere la siguiente forma:
\begin{itemize}
 \item Calcular \emph{la media} $\mu_i$ y \emph{varianza} $\sigma_{i}^2$ para cada característica $i$ en los datos del conjunto de entrenamiento $X$.
 \begin{itemize}
  \item Las formulas son las siguientes, con $X_i$ la columna con la i-ésima característica en los datos de entrenamiento $X$.\\
  \begin{equation}
   \mu_{i} = \dfrac{1}{m}\sum_{i=1}^{m}x_{i} 
  \end{equation}
  \begin{equation}
   \sigma_{i}^{2} = \dfrac{1}{m}\sum_{i=1}^{m}(x_{i}-\mu)^2 
  \end{equation}
  \begin{equation}
   X_{i} = \dfrac{X_{i}-\mu}{\sigma^{2}}
  \label{eq:tres}
  \end{equation}
 \end{itemize}
    \item La media es el promedio de los datos de entrada.
    \item La varianza es una medida de dispersión, para ver que tan separados estan los datos unos de otros.
    \item La reasignación para cada $X_i$ va a ser, la resta $X_i -\mu$, que va a centrar los datos alrededor del cero, y la división por la varianza $\sigma^2$ que va a encoger los intervalos de distancia entre los datos. 
\end{itemize}

 
\begin{itemize}
 \item Una vez que la red se entreno con datos normalizados, \textit{es necesario almacenar las medias y varianzas} utilizadas durante el entrenamiento con el conjunto de entrenamiento $X$.
 \item Estos valores serán utilizados para normalizar datos nuevos que vayan a ser evaluados en la red. Esto para evitar que los nuevos datos usen magnitudes fuera del intervalo usado durante el entrenamiento de la red.
\end{itemize}

\begin{definition}
 \emph{La normalización} permite reducir la excentricidad en la función de error provocada por la disparidad entre los datos de entrada.
\end{definition}
  
 Entonces ya tenemos resuelta la situación de la disparides entre los datos de entrada. Ahora tenemos que, al calcular los valores para las capas intermedias, los valores pueden cambiar sus rangos para las neuronas intermedias. Para esta situación tenemos la normalización por lotes (\emph{bach normalization} en inglés).
 
La normalización por lotes aplica los beneficios de la normalización a las capas intermedias, haciendo que estás den valores en intervalos no muy grandes para las siguientes capas.

Una ventaja que nos da esta herramienta es que los algoritmos de optimización podrán utilizar \textit{tazas de aprendizaje más altas}, porque los brincos discretos del algoritmo no cambiarán drásticamente el comportamiento de la función de error durante un intervalo más largo.

Otra ventaja es que al normalizar entre capas, permite que cada capa calcule características distintas, independientemente que se otorguen ejemplares con mucho sesgo en una característica en especial. Permitiendo una mejor clasificación aún con datos nuevos. 

\begin{definition}
 La \emph{normalización por lotes} conciste en: 
 \begin{enumerate}
  \item  Normalizar la salida de la capa de activación anterior restando su media y dividiendo entre la desviación estándar.
  \item Hacer descenso por el gradiente estocástico.
  \item Dos paremetros: $\gamma$ una desviación estandar y $\beta$ una media para corrimiento.
 \end{enumerate}
\end{definition}

Cuando se use el descenso por el gradiente estocástico (el descenso por el gradiente por lotes) modificará los pesos para optimizar $J$ la función de error, y probablemente contrarreste el efecto de la normalización.
Para evitarlo, se añaden dos parámetros, también entrenables: $\gamma$ una desviación estándar y $\beta$ una media para corrimiento, la idea es que el algoritmo tienda a
modificarlos, $\gamma$ para escalarlos y $\beta$ para sesgar los datos, en lugar de a los pesos, de modo que los pesos produzcan un cómputo más estable.

Entonces la idea concreta es que dado un minilote $B$ con $x_i$ sus ejemplares, las entradas $y_i$ para la capa siguiente se
calculan con las siguientes formulas:
  \begin{equation}
   \mu_{B} = \dfrac{1}{m}\sum_{i=1}^{m}x_{i} 
  \end{equation}
  \begin{equation}
   \sigma_{B}^{2} = \dfrac{1}{m}\sum_{i=1}^{m}(x_{i}-\mu_{B})^2 
  \end{equation}
  \begin{equation}
   x_{i} = \dfrac{X_{i}-\mu_{B}}{\sqrt{ \sigma_{B}^{2} + \varepsilon}}
  \label{eq:tres}
  \end{equation}
  \begin{equation}
   y_{i} = \gamma x_{i}+\beta \equiv BN_{\gamma,\beta}(x_{i})
  \label{eq:tres}
  \end{equation}

con $\varepsilon$ una constante agregada para mantener la estabilidad numérica.

Una vez que hayamos hecho la normalización y hecho la reasignación de datos, nos va a dar los nuevos $y_i$'s que van a entrar para participar en la combinación lineal que decide si se activan o no las neuronas de la siguiente capa. Los valores gama y beta nos van a permitir desnormalizar los datos. 

Así llegamos a la parte de \emph{inferencia}, una vez entrenada la red con normalización y normalización por lotes. Vamos a querer usar la red para hacer inferencias, para esto vamos a calcular la media y la varianza sobre los \textit{mini lotes de entrenamiento} la diferencia más grande con respecto a lo  anterior la vamos a tener en el cálculo de la varianza, porque se utiliza la variante sin sesgos, estos valores se van a estimar con los mini lotes del conjunto de entrenamiento y estos van a quedar como \textit{constantes fijas}. Cuando entren los nuevos valores que estamos tratando de evaluar con nuestra red neuronal, ya no vamos a calcular otra vez las $\mu$ y $\sigma$ para las capas intermedias. Sino que vamos a utilizar:

  \begin{equation}
   E[x] = E_{B}[\mu_{B}]
  \end{equation}
  \begin{equation}
   Var[x] = \dfrac{m}{m-1}E_{B}[\sigma_{B}^2] 
  \end{equation}
  

Que son los promedios con los mini lotes que entrenamos, entonces  los valores modificados de los valores de activación de cada capa van a estar dados por:

\begin{equation}
 y = x \dfrac{\gamma}{\sqrt{Var[x]+\varepsilon} } + % \left(\beta-\dfrac{\gammaE[x]}{\sqrt{Var[x] + \varepsilon} } \right)
\end{equation}

Donde $y$ toma el valor $x$ de activación con una red neuronal normal después multiplicarlo por el parámetro gamma (que ya tuvo que haber sido aprendido por el algoritmo de entrenamiento) se va a dividir entre esta desviación estándar pero calculada sobre los datos estadísticos el de lo que salió en esas capas intermedias cuando estábamos realizando el entrenamiento. 

Entonces en resumen la idea es la siguiente, dada  una capa de la red neuronal con sus valores de activación, antes de pasar a la siguiente capa tenemos que pasar por un proceso por un proceso, \textit{la normalización} para ese proceso necesitábamos la media y la varianza. Sin embargo mientras estábamos entrenando esta media y esta varianza podían ser alterados porque estamos modificando los pesos eso modifique los valores que se estaban calculando aquí y por consiguiente  estos dos se van a volver a modificar. Una vez que ese proceso ya terminó y ya decidimos que están fijos los pesos ya tenemos los valores de beta y gamma que vamos a utilizar, es cuando se va a proceder a calcular  la última versión de las medias y las varianzas, con los datos de entrenamiento. 

Cuando tengamos ya estos valores estables porque ya no estamos modificando nada en la red estos los vamos a guardar y se van a convertir en los valores que vamos a utilizar cuando queramos evaluar un dato nuevo sobre la red que ya está entrenada entonces ahora sí cuando llegue a un dato nuevo cada vez que pasemos por alguna de las capas intermedias vamos a tomar esos valores de activación y vamos a aplicar lo equivalente a la fórmula que teníamos antes esta que está aquí nada más que ahora vamos a utilizar estas constantes que se derivan del escalamiento que tuvimos que hacer cuando estábamos entrenando entonces esto que está acá va a ser el valor que va a entrar a la siguiente capa de la red en lugar de haber utilizado el valor de activación como y una vez que hayamos hecho esto entonces nuestra red también va a tener el mismo tipo de normalización para datos que no habían estado en el conjunto de entrenamiento y además pues ésta es normalización es ya no van a estar cambiando porque dependen nada más de los parámetros. 

La mayoría de las apis para el desarrollo de redes neuronales ya tienen estos calculos programados por detrás y nosotros realmente lo único  tenemos que hacer es programarla como una capa, que se le conoce como \textit{capa de normal por lotes}. 

%Para más información también pueden aseguir las siguientes ligas:
%\begin{itemize}
% \item \url{https://www.analyticsvidhya.com/blog/2021/03/introduction-to-batch-normalization/}
% \item \url{https://www.baeldung.com/cs/normalizing-inputs-artificial-neural-network}
% \item \url{https://towardsdatascience.com/why-data-should-be-normalized-before-training-a-neural-network-c626b7f66c7d}
%\end{itemize}

