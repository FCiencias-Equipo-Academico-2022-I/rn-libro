\section{Esquema general entrenamiento}
 
 En este capítulo vamos a trabajar con el entrenamiento (específicamente por retropropagación), en esta sección abordaremos primero el esquema general del entrenamiento. 
 A lo largo del capítulo veremos la derivación del primer algoritmo de entrenamiento para perceptrones multicapa (este es de los más comunes en esta área y el primero descrito propiamente).

En el tercer capítulo habíamos visto el concepto de aprendizaje para una máquina, ahora vamos a definir en que consiste aprender algo en el campo de las redes neuronales. Retomando lo descrito en ese capítulo, recordemos que aprender para un modelo es más que nada encontrar una función que se asemeje a ciertas salidas específicas, está función está dentro de un espacio de funciones posibles propuestas. La función que deseamos encontrar modela algún tipo de tarea que nos interesa que se aprenda. 

\begin{definition}
 \textbf{El problema de aprendizaje para un perceptrón multicapa:} Dada una arquitectura de red neuronal, encontrar los pesos tales que la función $h\Theta(\vec{x}) $ (definida por la red neuronal) aproxime, hasta cierta tolerancia, la función de interés $ f(\vec{x})$. \\ Con $\vec{x}$ los datos de entrada.
 
\end{definition}

En la definición anterior, el vector $\vec{x}$, consisten en distintas características de los ejemplares provistos, según sea el problema a resolver, por ejemplo:
\begin{itemize}
 \item Segmentos de alguna canción.
 \item Píxeles de imágenes.
 \item Valores equivalentes a precios del mercado.
\end{itemize}

En este momento nos estamos concentrando en problemas de clasificación así que estás redes estan clasificando los ejemplares según ciertas características. Estas clasificaciones pueden ser muy interesantes, algunas por ejemplo se pueden dedicar a clasificar canciones, identificando ciertas emociones que transmiten como tristeza o alegria. 

Nuestra red neuronal va empezar sus calculos apartir de los datos de entrada $\vec{x}$, entonces al finalizar cada uno de los ejemplares va a ser mapeado a alguna clase (en el espacio de clases). Por medio de una función donde $f(x)$ es nuestra función ideal que hacer el mapeo exacto los ejemplares a su clase. Así si logramos que nuestra función $h\Theta(\vec{x})$ se aproxime a $f(x)$, la red neuronal nos daría las respuestas esperadas dado ciertos ejemplares, como por ejemplo:
\begin{itemize}
 \item Dado unas imagenes de distintas plantas, identificar correctamente el nombre de cada una.
 \item Dado una fragmento de canción indicarnos su genero.
 \item Dada una oración identificar si contiene un mensaje de odio.
\end{itemize}

Entonces el reto de la red neuronal es aproximar una función $f(x)$ (que se asume existe en el universo),
primero debemos intentar calcular $h\Theta(\vec{x})$ (\emph{h} de hipótesis, de un espacio de hipótesis). Está hipotesis puede que aproxime muy bien la función pero en la mayoria de los casos no es así, entonces iremos haciendo ajustes a los pesos (que definen la función h) para que pueda aproximarse lo más posible a nuestra función objetivo.


Como en muchos casos vamos a intentar aproximar funciones que no corresponden a un concepto matemático, sino más a percepciones humanos tales como sentimientos o clasificar abstraciones humanas, entonces se puede dar el caso que realemente no se pueda aproximar con total exactitud la función y le demos un cierto \emph{grado de tolerancia}, donde asume que se pueda dar ciertos errores en ciertos ejemplares. Dependiendo del contexto vamos a asignar el rango de tolerancia a errores.

Es importante notar que si los datos de entrenamiento resultan clasificados con mucha precisión es probable que la red este aprendiendo datos no utlies para la tarea dada es decir ese aprendiendo \emph{ruido}. Y al momento de prueba no nos entregue buenos restultados.

Ahora vamos a ver que tenemos que \emph{entrenar} una red para que se aproxime cada vez más a la función objetivo, que consiste en lo siguiente:
\begin{itemize}
 \item  Definir una \emph{función de error} o pérdida $J$ (o $L$ de lost perdida en íngles) que mida la distancia entre los valores
deseados y los valores obtenidos con un conjunto de pesos dados $\Theta$ .
 \item Utilizar alguna \emph{técnica de optimización} de funciones que minimize este error.
 \item Tanto la arquitectura a considerar, como la función de error y la técnica de
optimización dependerán del tipo de función que se desee aproximar.
\end{itemize}

Una vez que ya sabemos en que consiste el entrenamiendo veamos un esquemas general conocido como \emph{entranamiento por retropropagación} o \textit{Backpropagation} en íngles. Anteriormente habíamos visto la evalución de una red con \textit{feedforward} que es de izquierda a derecha, ahora con la retroprogación vamos a recorrer la red de derecha a izquierda, de la siguiente forma:
\begin{itemize}
 \item Utilizar \emph{la regla de la cadena} para obtener el gradiente de la función de error con
respecto al conjunto de pesos, dado un conjunto de datos de entrenamiento \emph{$X$} con sus etiquetas \emph{$Y$}.
\item Utilizar \emph{descenso por el gradiente} para encontrar un mínimo, lo suficientemente
bueno, de la función de error. Está técnica es la más sencilla, por eso usualmente se utilizaba en un principio
\begin{itemize}
 \item La idea es que al inicio no sabemos cuánto deben de valer los pesos para modelar correctamente la función, entonces vamos a comenzar con una asignación aleatoria de pesos. Tenemos un conjunto de pesos ideales a los cuales queremos aproximar nuestros pesos aleatorios. Así calculamos el error que tiene nuestros pesos, haciendo las comparaciones con los datos que se obtuvieron al aplicar el feedforward sobre los datos de entrada con los datos esperados. El desenso por el gradiente va modificar poco a poco los pesos para tengamos ahora una nueva aproximación y nos acerquemos más a una región donde el error sea más pequeño.
 Para calcular el descenso por el gradiente, se calculan las derivadas de la función de error con respecto a los parámetros. 
 \item Entonces tenemos una actualización de la siguiente forma: 
    \begin{equation}
     Theta' = Theta - \alpha \nabla_{\Theta}J
    \end{equation}
        Donde \emph{Theta} es la propuesta para nuestros parametros iniciales, $\nabla_{\Theta}$ es el gradiente que nos da el máximo acenso de la función de error, el cúal lo invertimos con el menos, para que siempre nos dirijamos al minimo local más proximo.  
\end{itemize}
\item Actualmente se puede cambiar la técnica de optimización por algún otro método
más avanzado, también depende del gradiente.

\item La derivación original utilizaba diferencias al cuadrado como función de error. Sin
embargo se ha comprobado que esa función es adecuada para problemas de
regresión, pero para problemas de clasificación es mejor utilizar entropía cruzada.
\item Se puede consultar la derivación del gradiente para diferencias al cuadrado en
Russell y Norving
\end{itemize}

Como se entrena entonces realmente una red neuronal bueno como el mínimo el que lleguemos depende de el conjunto original que hayamos dado de parámetros es para el entrenamiento lo que vamos a hacer es inicializar aleatoriamente estos datos para obtener puntos en diferentes regiones del espacio y repetir el entrenamiento varias veces. Aquí el entrenamiento que nos logre llevar al mejor mínimo que satisfagan nuestros requerimientos de haber aproximado lo suficientemente bien la función. Ese es el conjunto con el que nos vamos a quedar una vez que ya hemos evaluado nuestra red y que hemos visto que es buena para hacer predicciones. Inclusive en otros conjuntos de datos que no sean con los que entrenamos y así que para eso nos sirve el conjunto de validación. 

Entonces podremos decir que ya tenemos una red que podemos utilizar para hacer adicciones en otras versiones algunos sistemas a la mejor hasta podrían guardar una colección de las redes que quedaron mejores entrenadas y 
 
 utilizar algún sistema de votación para tomar decisiones al momento de utilizarlas ya en producción lo que estamos viendo aquí a la derecha es una imagen de los cortes que se podrían hacer horizontalmente de esta misma imagen entonces también 
 Podemos visualizar a nuestro conjunto de parámetros z y coordenadas sobre este plano y en estas que son las curvas de nivel podemos ir tratar todo visualizar buenas ya que hasta el mínimo hacía que estaría como está subiendo el paraboloide y podemos ver también como la dirección negativa del gradiente pues nos iría dirigiendo poco a poco hacia este centro donde tenemos uno entonces actualmente se puede cambiar la técnica de optimización por algún otro método más avanzado también dependiente del gradiente el hecho de que depende del gradiente pues va a ser que en la siguiente sección sea sumamente importante que es como calculamos el gradiente de la función de error la derivación original utilizaba diferencias al cuadrado como función de error recordemos que es aquella en la que deseamos cuánto es lo que quiero obtener .
 
 menos mi hipótesis de lo que evalúa un mínimo función de la red neuronal sobre los datos elevados al cuadrado y después sumamos sobre todas las y todos los ejemplares entonces esta fue la primera que se utilizó sin embargo se ha comprobado que esta función es adecuada para problemas de regresión pero para problemas de clasificación es mejor utilizar otra que se le conoce como entropía cruzada y ven artículos un poco viejitos o inclusive de otros campos van a ver que es muy frecuente encontrar diferencias al cuadrado por ello si quieren ver esa derivación se puede consultar en el libro de rosalino link les recomiendo la tercera edición creo que la anotación es más clara en la tercera edición que en la segunda lo que vamos a hacer nosotros aquí es ver la derivación con entropía cruzada que es básicamente ya el estándar cuando queremos empezar a trabajar con problemas de clasificación vamos a ver también que tiene algunas propiedades bastante bonitas y nos va a facilitar las cosas.
